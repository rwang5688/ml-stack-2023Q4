{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install huggingface_hub\n",
    "! pip install torch==2.0.1+cu118 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "! pip install transformers\n",
    "! pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pre-trained model\n",
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model=\"rwang5688/distilgpt2-finetuned-wikitext2-pt\")\n",
    "set_seed(42)\n",
    "generator(\"What is Amazon SageMaker Studio?\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install AWS packages\n",
    "! pip install boto3\n",
    "! pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set profile name as opposed to entering credentials\n",
    "# profile_name = 'default'\n",
    "region_name = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and test sagemaker client\n",
    "import boto3 \n",
    "# session = boto3.Session(profile_name=profile_name)\n",
    "session = boto3.Session()\n",
    "sm_client = session.client('sagemaker', region_name=region_name)\n",
    "response = sm_client.list_endpoints()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name and endpoint configuration name\n",
    "import time\n",
    "ml_model_name = \"distilgpt2-pt\"\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = ml_model_name + '-model' + timestamp\n",
    "endpoint_config_name = ml_model_name + '-epc' + timestamp\n",
    "endpoint_name = ml_model_name + '-ep' + timestamp\n",
    "print(model_name)\n",
    "print(endpoint_config_name)\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sagemaker execution role\n",
    "import sagemaker\n",
    "# create a sagemaker execution role via the AWS SageMaker console, then paste in the arn here\n",
    "role = 'arn:aws:iam::123456789012:role/sagemaker-execution-role'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see deep learning containers (DLC) available images here:\n",
    "# https://github.com/aws/deep-learning-containers/blob/master/available_images.md \n",
    "model_image_url=\"763104351884.dkr.ecr.\"+region_name+\".amazonaws.com/\"+\\\n",
    "                \"huggingface-pytorch-inference:1.13.1-transformers4.26.0-cpu-py39-ubuntu20.04\"\n",
    "print(model_image_url)\n",
    "\n",
    "# set container config\n",
    "container_config = {\n",
    "    'Image': model_image_url,\n",
    "    'Mode': 'SingleModel',\n",
    "    'Environment': {\n",
    "        'HF_MODEL_ID': 'rwang5688/distilgpt2-finetuned-wikitext2-pt',\n",
    "        'HF_TASK' : 'text-generation',\n",
    "        'SAGEMAKER_CONTAINER_LOG_LEVEL' : '20',\n",
    "        'SAGEMAKER_REGION' : region_name\n",
    "    }\n",
    "}\n",
    "print(container_config)\n",
    "\n",
    "# create model\n",
    "# ... models console: https://console.aws.amazon.com/sagemaker/home?#/models\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer=container_config,\n",
    "    ExecutionRoleArn=role, \n",
    "    EnableNetworkIsolation=False\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create endpoint config\n",
    "# ... endpoint configs console: https://console.aws.amazon.com/sagemaker/home?#/endpointConfig\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "   EndpointConfigName=endpoint_config_name,\n",
    "   ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ServerlessConfig\": {\n",
    "                # Specify MemorySizeInMB and MaxConcurrency in the serverless config object\n",
    "                \"MemorySizeInMB\": 3072,\n",
    "                \"MaxConcurrency\": 10\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(endpoint_config_response)\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create endpoint\n",
    "# ... endpoints console: https://console.aws.amazon.com/sagemaker/home?#/endpoints\n",
    "endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(endpoint_response)\n",
    "\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "print('Endpoint arn:  {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAIT FOR ENDPOINT TO BE \"IN SERVICE\" BEFORE PROCEEDING WITH THIS STEP\n",
    "\n",
    "# invoke endpoint by endpoint name\n",
    "import json\n",
    "sm_runtime = session.client(\"sagemaker-runtime\", region_name=region_name)\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "# specify \"Inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"What is Amazon SageMaker Studio?\"\n",
    "}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=json.dumps(data)\n",
    ")\n",
    "print(response)\n",
    "print(response[\"Body\"].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up: uncomment the following lines\n",
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "#sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "#sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
